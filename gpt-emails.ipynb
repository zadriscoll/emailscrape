{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "base_url = 'https://www.lfmgcpas.com/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Scraping https://www.lfmgcpas.com/\n",
      "Scraping https://www.lfmgcpas.com/firmprofile.php\n",
      "Scraping https://www.lfmgcpas.com/custom.php\n",
      "Scraping https://www.lfmgcpas.com/custom2.php\n",
      "Scraping https://www.lfmgcpas.com/custom3.php\n",
      "Scraping https://www.lfmgcpas.com/client-reviews.php\n",
      "Scraping https://www.lfmgcpas.com/services.php\n",
      "Scraping https://www.lfmgcpas.com/custom5.php\n",
      "Scraping https://www.lfmgcpas.com/taxprepplan.php\n",
      "Scraping https://www.lfmgcpas.com/estate.php\n",
      "Scraping https://www.lfmgcpas.com/accountingservices.php\n",
      "Scraping https://www.lfmgcpas.com/lfmgservices.php\n",
      "Scraping https://www.lfmgcpas.com/traditional.php\n",
      "Scraping https://www.lfmgcpas.com/nontraditional.php\n",
      "Scraping https://www.lfmgcpas.com/newsletter.php\n",
      "Scraping https://www.lfmgcpas.com/archive.php\n",
      "Scraping https://www.lfmgcpas.com/dailynews.php\n",
      "Scraping https://www.lfmgcpas.com/life-events.php\n",
      "Scraping https://www.lfmgcpas.com/business-strategies.php\n",
      "Scraping https://www.lfmgcpas.com/taxstrategies-businessowners.php\n",
      "Scraping https://www.lfmgcpas.com/taxstrategies-individuals.php\n",
      "Scraping https://www.lfmgcpas.com/investment-strategies.php\n",
      "Scraping https://www.lfmgcpas.com/frequently-asked-questions.php\n",
      "Scraping https://www.lfmgcpas.com/taxcenter2.php\n",
      "Scraping https://www.lfmgcpas.com/taxrefunds.php\n",
      "Scraping https://www.lfmgcpas.com/taxduedates.php\n",
      "Scraping https://www.lfmgcpas.com/taxddform.php\n",
      "Scraping https://www.lfmgcpas.com/taxrates2.php\n",
      "Scraping https://www.lfmgcpas.com/taxpublications.php\n",
      "Scraping https://www.lfmgcpas.com/taxretention.php\n",
      "Scraping https://www.lfmgcpas.com/statetaxforms.php\n",
      "Scraping https://www.lfmgcpas.com/taxorganizer.php\n",
      "Scraping https://www.lfmgcpas.com/tax_reform_info.php\n",
      "Scraping https://www.lfmgcpas.com/resources.php\n",
      "Scraping https://www.lfmgcpas.com/calc-section.php\n",
      "Scraping https://www.lfmgcpas.com/quick-send.php\n",
      "Scraping https://www.lfmgcpas.com/links.php\n",
      "Scraping https://www.lfmgcpas.com/contact.php\n",
      "Scraping https://www.lfmgcpas.com/custom4.php\n",
      "Scraping https://www.lfmgcpas.com/index.php\n",
      "Scraping https://www.lfmgcpas.com/about.php\n",
      "Scraping https://www.lfmgcpas.com/taxservices.php\n",
      "Scraping https://www.lfmgcpas.com/indservices.php\n",
      "Scraping https://www.lfmgcpas.com/bizservices.php\n",
      "Scraping https://www.lfmgcpas.com/sitemap.php\n",
      "Scraping https://www.lfmgcpas.com/privacy.php\n",
      "Scraping https://www.lfmgcpas.com/disclaimer.php\n",
      "Scraping https://www.lfmgcpas.com/julie.php\n",
      "Scraping https://www.lfmgcpas.com/claudia.php\n",
      "Scraping https://www.lfmgcpas.com/upevents2.php\n",
      "Scraping https://www.lfmgcpas.com/rssfeed.php\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/bs4/builder/__init__.py:545: XMLParsedAsHTMLWarning: It looks like you're parsing an XML document using an HTML parser. If this really is an HTML document (maybe it's XHTML?), you can ignore or filter this warning. If it's XML, you should know that using an XML parser will be more reliable. To parse this document as XML, make sure you have the lxml package installed, and pass the keyword argument `features=\"xml\"` into the BeautifulSoup constructor.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Scraping https://www.lfmgcpas.com/about.php\n",
      "Scraping https://www.lfmgcpas.com/margaret.php\n",
      "Scraping https://www.lfmgcpas.com/cynthia.php\n",
      "Scraping https://www.lfmgcpas.com/Sherri.php\n",
      "Scraping https://www.lfmgcpas.com/personalfinplan.php\n",
      "Scraping https://www.lfmgcpas.com/estateplan.php\n",
      "Scraping https://www.lfmgcpas.com/eldercare.php\n",
      "Scraping https://www.lfmgcpas.com/smallbiz.php\n",
      "Scraping https://www.lfmgcpas.com/qbmain.php\n",
      "Scraping https://www.lfmgcpas.com/whyquickbooks.php\n",
      "Scraping https://www.lfmgcpas.com/quickbookssetup.php\n",
      "Scraping https://www.lfmgcpas.com/qbtraining.php\n",
      "Scraping https://www.lfmgcpas.com/quickanswers.php\n",
      "Scraping https://www.lfmgcpas.com/quicktuneup.php\n",
      "Scraping https://www.lfmgcpas.com/quickbookstips.php\n",
      "Scraping https://www.lfmgcpas.com/buyquickbooks.php\n",
      "Scraping https://www.lfmgcpas.com/payrollservice.php\n",
      "Scraping https://www.lfmgcpas.com/cfoservices.php\n",
      "Scraping https://www.lfmgcpas.com/auditing.php\n",
      "Scraping https://www.lfmgcpas.com/cashmanagement.php\n",
      "Scraping https://www.lfmgcpas.com/bankfinancing.php\n",
      "Scraping https://www.lfmgcpas.com/valuation.php\n",
      "Scraping https://www.lfmgcpas.com/bizplan.php\n",
      "Scraping https://www.lfmgcpas.com/succession.php\n",
      "Scraping https://www.lfmgcpas.com/formation.php\n",
      "Scraping https://www.lfmgcpas.com/nonprofit.php\n",
      "Scraping https://www.lfmgcpas.com/internalcontrols.php\n",
      "Scraping https://www.lfmgcpas.com/taxprep.php\n",
      "Scraping https://www.lfmgcpas.com/taxplanning.php\n",
      "Scraping https://www.lfmgcpas.com/irs-problemshome.php\n",
      "Scraping https://www.lfmgcpas.com/irs-representation.php\n",
      "Scraping https://www.lfmgcpas.com/irs-nonfiledreturns.php\n",
      "Scraping https://www.lfmgcpas.com/irs-backtaxes.php\n",
      "Scraping https://www.lfmgcpas.com/irs-payrolltax.php\n",
      "Scraping https://www.lfmgcpas.com/irs-taxliens.php\n",
      "Scraping https://www.lfmgcpas.com/irs-taxlevies.php\n",
      "Scraping https://www.lfmgcpas.com/irs-garnishment.php\n",
      "Scraping https://www.lfmgcpas.com/irs-taxseizures.php\n",
      "Scraping https://www.lfmgcpas.com/irs-offercompromise.php\n",
      "Scraping https://www.lfmgcpas.com/irs-paymentplan.php\n",
      "Scraping https://www.lfmgcpas.com/irs-taxbankruptcy.php\n",
      "Scraping https://www.lfmgcpas.com/irs-spouse.php\n",
      "Scraping https://www.lfmgcpas.com/irs-files.php\n",
      "Scraping https://www.lfmgcpas.com/custom1.php\n",
      "Scraping https://www.lfmgcpas.com/search.php\n",
      "Scraping https://www.lfmgcpas.com/quickbookstips.php\n",
      "Scraping https://www.lfmgcpas.com/quickbookstips.php\n",
      "Scraping https://www.lfmgcpas.com/buyquickbooks.php\n",
      "Scraping https://www.lfmgcpas.com/buyquickbooks.php\n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import csv\n",
    "import re\n",
    "from urllib.parse import urljoin\n",
    "import datetime\n",
    "\n",
    "# Define a function to scrape a single web page for email addresses and names\n",
    "def scrape_page(url):\n",
    "    # Send a GET request to the URL\n",
    "    headers = {\n",
    "    \"User-Agent\": \"Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/105.0.0.0 Safari/537.36\"\n",
    "    }\n",
    "    response = requests.get(url, headers = headers)\n",
    "    if response.status_code == 200:\n",
    "        return BeautifulSoup(response.text, 'html.parser')\n",
    "    else:\n",
    "        return None\n",
    "    \n",
    "def find_internal_links(soup, base_url):\n",
    "    links = []\n",
    "    excluded_keywords = ['subscribe','portal','reports','google','#','?']\n",
    "    for a in soup.find_all('a', href=True):\n",
    "        link = urljoin(base_url, a['href'])\n",
    "        # Exclude links to image files\n",
    "        if link.endswith('.jpg') or link.endswith('.jpeg') or link.endswith('.png') or link.endswith('.gif') or link.endswith('.pdf'):\n",
    "            continue\n",
    "        if any(keyword in link for keyword in excluded_keywords):\n",
    "            continue\n",
    "        # if not link.endswith('/'):\n",
    "        #     continue\n",
    "        if link.startswith(base_url):\n",
    "            links.append(link)\n",
    "    return links\n",
    "\n",
    "def extract_emails_and_first_names(soup, scraped_emails):\n",
    "    links = soup.find_all('a', href=True)\n",
    "    emails = []\n",
    "    email_pattern = r'\\b(?!hr@|sales@)[A-Za-z0-9._%+-]+@[A-Za-z0-9.-]+\\.[A-Z|a-z]{2,}\\b'\n",
    "    for link in links:\n",
    "        href = link.get('href')\n",
    "        if href and href.startswith('mailto:'):\n",
    "            email = href.replace('mailto:', '').strip()\n",
    "            if re.match(email_pattern, email) and email not in scraped_emails:\n",
    "                first_name = email.split('@')[0].split('.')[0]\n",
    "                emails.append((first_name, email))\n",
    "    \n",
    "    if not emails:\n",
    "        email_pattern = r'\\b(?!hr@|sales@)[A-Za-z0-9._%+-]+@[A-Za-z0-9.-]+\\.[A-Z|a-z]{2,}\\b'\n",
    "        paragraphs = soup.find_all('p')\n",
    "        paragraph_texts = ' '.join([p.get_text() for p in paragraphs])\n",
    "        emails = re.findall(email_pattern, paragraph_texts)\n",
    "        first_names = [email.split('@')[0].split('.')[0] for email in emails]\n",
    "        emails = [(first_name, email) for first_name, email in zip(first_names, emails) if email not in scraped_emails]\n",
    "    \n",
    "    return emails\n",
    "\n",
    "def main():\n",
    "    today = datetime.datetime.now().strftime('%Y-%m-%d')\n",
    "    match = re.search(r\"www\\.(.*?)\\.com\", base_url)\n",
    "    if match:\n",
    "        company_name = match.group(1)\n",
    "    csv_filename = f'{company_name}{today}_emails.csv'\n",
    "    visited_links = set()\n",
    "    links_to_visit = [base_url]\n",
    "    scraped_emails = set()  # Keep track of unique emails\n",
    "    \n",
    "    with open(csv_filename, 'w', newline='') as csvfile:\n",
    "        writer = csv.writer(csvfile)\n",
    "        writer.writerow(['First Name', 'Email'])\n",
    "        \n",
    "        while links_to_visit:\n",
    "            link = links_to_visit.pop(0)\n",
    "            if link not in visited_links:\n",
    "                print(f\"Scraping {link}\")\n",
    "                soup = scrape_page(link)\n",
    "                if soup:\n",
    "                    visited_links.add(link)\n",
    "                    links_to_visit.extend(find_internal_links(soup, base_url))\n",
    "                    emails_and_first_names = extract_emails_and_first_names(soup, scraped_emails)\n",
    "                    for first_name, email in emails_and_first_names:\n",
    "                        if email not in scraped_emails:  # Check if email has already been scraped\n",
    "                            writer.writerow([first_name, email])\n",
    "                            scraped_emails.add(email)  # Add email to set of scraped emails\n",
    "\n",
    "                        \n",
    "if __name__ == \"__main__\":\n",
    "    main()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
